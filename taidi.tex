\documentclass[UTF8]{ctexart}
\title{题目}
\author{林一凡\quad王佳璇\quad万宗祺}
\date{\today}
\usepackage{amsthm}
\usepackage{geometry}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{amsmath}
\geometry{left = 3.5cm,right=3.5cm,top=2.5cm,bottom=2.5cm}
\usepackage{cite}
\begin{document}

\maketitle
\begin{abstract}
\begin{flushleft}
\textbf{关键词：} RNN;LSTM;中文分词;词嵌入
\end{flushleft}
\end{abstract}

\tableofcontents
\section{引言}
近年来，随着互联网产业的迅猛发展，人们接触到的信息量越来越庞大，对高效的信息检索能力的需求日益旺盛。对一篇文本，我们希望不必亲自阅读就能直接得到我们想要的问题的答案所在的句子或者段落，要达到这个目的，仅仅靠简单的词语匹配是不行的，这促使了问答系统研究的产生与发展，在智能阅读模型中，我们要做的是对候选答案句进行确认，标记出正确答案所在的句子，中文候选答案句确认的研究进展目前不及英文候选答案句确认的进展，因为中文句子在分词上面比英文句子难度大得多，而且中文的语法比英文更复杂，表达方式也更加丰富，这些都是中文问答系统的难点。

早期的答案抽取研究一般是基于规则的答案匹配，以及提取特征并利用传统机器学习算法进行监督学习，而在近几年，由于深度学习的兴起，利用深度学习解决答案抽取问题成为了主流方法，它可以绕过人工构造特征的繁琐过程，自动学习到自然语言中的深层特征，从而正确地识别出正确答案所在句子。

本文阐述我们如何利用传统机器学习和LSTM等模型构建一个智能阅读系统。
\section{数据预处理}
\subsection{数据均衡化}
经过初步统计，我们发现，训练集中的答案句有28\%是正确答案句，剩下的72\%是错误答案句，正反例的不平衡无疑会对训练模型产生非常不好的影响，模型可能会将所有的句子全部判定为错误答案句，这样就已经能够取得72\%的正确率了。

常见的处理正负例不均衡的方法有过采样法和降采样法。过采样即随机地重复采样正例从而使正负例数量相同，而降采样就是把一部分负例从训练集中去除，从而使得正例与负例达到均衡。

考虑到如果采取降采样法，将会损失大量数据，所以我们采取了过采样法。
\subsection{句子的分词}
在中文句子中，一个“语义”的单元是一个词语，这意味着我们需要首先把句子分解成词语，这方面的研究已经发展的比较完善了，目前已经有几个开放的自然语言处理工具能在分词任务上取得不错的效果了，比如结巴分词，哈工大自然语言处理工具ltp，中科院分词工具ICTCLAS。我们选择了结巴分词来处理数据。
\subsection{句子的向量表示}
经过分词之后，句子可以看作是词语的序列，对句子的向量表示就是对词语的向量表示问题。

词语最简单的表示方法就是one-hot向量，它将词典的长度作为向量的长度，而只在该向量对应词在词典中的编号对应的向量位置标为1，其它位置都标为0。例如词语“人群”在词典的第3个位置，那么它对应的one-hot向量表示就为[0,0,1,0,0,$\cdots$]。

one-hot向量虽然能简单地完成对词语的表示任务，但是它存在两个弊端，一个是它将不同的词语判定为完全不同，譬如“土豆”与“马铃薯”，它们本来有同一个含义，但是在one-hot向量表示中，它们却是完全不同的，没有任何联系，这无疑会造成信息的大量丢失。第二个弊端是它的向量维度太过于庞大，词典中要包含训练集中所有的词语，那么one-hot向量可能会是几万甚至几十万维，这样庞大的维度不仅在空间还是时间上都将产生严重的性能损失
\end{document}